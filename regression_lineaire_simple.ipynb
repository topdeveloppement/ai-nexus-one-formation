{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/topdeveloppement/ai-nexus-one-machine-learning/blob/main/regression_lineaire_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "introduction",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "# 📊 Introduction à la Régression Linéaire Simple\n",
        "\n",
        "<div style=\"max-width: 800px; padding: 20px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); border-radius: 8px; background-color: #f9f9f9; margin: 20px auto;\">\n",
        "    <div style=\"display: flex; align-items: center; margin-bottom: 20px;\">\n",
        "        <div style=\"flex: 0 0 auto; margin-right: 15px;\">\n",
        "            <img src=\"https://github.com/topdeveloppement.png\" alt=\"Photo de l'auteur\" style=\"border-radius: 4px; width: 100px; height: 100px; object-fit: cover;\">\n",
        "        </div>\n",
        "        <div style=\"text-align: left;\">\n",
        "            <h3 style=\"margin: 0; font-size: 1.5em;\">Omar Kennouche</h3>\n",
        "            <p style=\"margin: 5px 0;\">Fonction : Chef de Projet Intelligence Artificielle et RPA</p>\n",
        "            <p style=\"margin: 5px 0;\">Entreprise : AI Nexus One</p>\n",
        "        </div>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 👤 Auteur : Omar Kennouche, fondateur de **AI Nexus One**\n",
        "\n",
        "**AI Nexus One** est un projet dédié à la **formation** et au **développement de solutions en intelligence artificielle**, visant à accompagner les entreprises dans l'exploitation des technologies avancées pour **optimiser leurs opérations** et **innover**.\n",
        "\n",
        "---\n",
        "\n",
        "### 🌐 Objectifs et Services\n",
        "\n",
        "AI Nexus One propose :\n",
        "- Une gamme complète de **modules de formation** sur des sujets comme le Machine Learning, la vision par ordinateur, et l’automatisation (RPA).\n",
        "- Des solutions **sur mesure** adaptées aux besoins des entreprises.\n",
        "- Un accompagnement pour faciliter l'**intégration pratique de l'IA** dans des domaines tels que les ressources humaines, la gestion des données et la relation client.\n",
        "\n",
        "---\n",
        "\n",
        "### 🤝 Vision\n",
        "\n",
        "En somme, **AI Nexus One** se veut un partenaire pour les entreprises cherchant à se démarquer dans un monde en évolution rapide, tout en conservant une approche **humaine** et **intuitive** des technologies.\n",
        "\n",
        "\n",
        "<div style=\"text-align: center; border-radius: 20px;\">\n",
        "    <img src=\"https://github.com/topdeveloppement/ai-nexus-one-machine-learning/blob/main/ml.jpeg?raw=true\" alt=\"Régression Linéaire\" style=\"width: 100%; height: auto;\">\n",
        "</div>\n",
        "\n",
        "# 🌟 La Régression Linéaire Simple\n",
        "\n",
        "La **régression linéaire simple** est une méthode statistique utilisée pour modéliser la relation entre une variable indépendante (explicative) et une variable dépendante (à prédire) en ajustant une droite aux données observées. Elle permet d’anticiper ou de comprendre comment la variable dépendante change en fonction de la variable indépendante.\n",
        "\n",
        "## 🎯 Définition et Objectifs\n",
        "\n",
        "- **Objectif principal** : Prédire ou estimer la valeur de la variable dépendante en fonction de la variable indépendante. Ce modèle aide à comprendre l’influence qu’a la variable explicative sur la variable à prédire, rendant les résultats compréhensibles et exploitables.\n",
        "- **Modélisation** : Identifier et ajuster la meilleure droite de régression, également appelée \"droite de tendance\", qui représente au mieux la relation linéaire entre les deux variables. Cette droite est calculée pour minimiser les écarts entre les valeurs observées et les valeurs prédites par le modèle.\n",
        "\n",
        "## 📈 Cas d'Utilisation et Exemples Concrets\n",
        "\n",
        "La régression linéaire simple est fréquemment utilisée dans divers domaines pour établir des prédictions et des analyses basées sur des données historiques. Voici quelques exemples :\n",
        "\n",
        "- 🔍 Prédire le **rendement d'une culture** agricole en fonction de la quantité de fertilisant utilisée.\n",
        "- 🌾 Estimer la **production de céréales** d'une coopérative en fonction du nombre d'adhérents.\n",
        "- 📊 Anticiper la **demande de marché** en fonction des tendances observées au cours des périodes précédentes.\n",
        "\n",
        "Ces exemples illustrent comment la régression linéaire simple peut être appliquée dans des situations réelles pour prévoir ou optimiser des résultats selon les variations d’une variable clé.\n",
        "\n",
        "## ⚙️ Hypothèses de Base\n",
        "\n",
        "Pour garantir des prédictions fiables, la régression linéaire simple repose sur plusieurs hypothèses :\n",
        "\n",
        "1. **📐 Linéarité** : La relation entre la variable indépendante et la variable dépendante est linéaire. Cela signifie que le changement dans la variable dépendante est proportionnel à celui de la variable indépendante.\n",
        "2. **🔗 Indépendance des erreurs** : Les résidus (ou erreurs) de prédiction sont indépendants les uns des autres, c’est-à-dire qu’il n’existe pas de corrélation entre les erreurs associées aux différentes observations.\n",
        "3. **⚖️ Homoscedasticité** : La variance des erreurs reste constante pour toutes les valeurs de la variable indépendante. En d'autres termes, les erreurs de prédiction n'augmentent ou ne diminuent pas systématiquement avec \\( X \\).\n",
        "4. **📊 Normalité des erreurs** : Les erreurs suivent une distribution normale, ce qui assure que les prévisions du modèle sont centrées et que les estimations des paramètres sont optimales.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "preparation-environnement",
      "metadata": {
        "id": "preparation-environnement"
      },
      "source": [
        "# 🛠️ Préparation de l'Environnement\n",
        "\n",
        "Dans cette section, nous allons :\n",
        "\n",
        "- 📦 Importer les bibliothèques nécessaires.\n",
        "- 📂 Charger les données d'exemple.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "importation-bibliotheques",
      "metadata": {
        "id": "importation-bibliotheques"
      },
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Paramètres d'affichage\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"Les bibliothèques ont été importées avec succès.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chargement-donnees",
      "metadata": {
        "id": "chargement-donnees"
      },
      "source": [
        "## 📊 Chargement des Données d'Exemple\n",
        "\n",
        "Pour cet exemple, nous allons créer un jeu de données synthétique simulant le rendement en céréales en fonction de la quantité de fertilisant utilisée.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "creation-dataset",
      "metadata": {
        "id": "creation-dataset"
      },
      "outputs": [],
      "source": [
        "# Création d'un dataset synthétique\n",
        "np.random.seed(42)\n",
        "n_samples = 100\n",
        "fertilizer = np.random.uniform(0, 100, n_samples)  # Quantité de fertilisant en kg/ha\n",
        "yield_cereals = 2 + 0.5 * fertilizer + np.random.normal(0, 5, n_samples)  # Rendement en tonnes/ha\n",
        "\n",
        "# Conversion en DataFrame pandas\n",
        "data = pd.DataFrame({'Fertilizer': fertilizer, 'Yield': yield_cereals})\n",
        "\n",
        "# Affichage des 5 premières lignes\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exploration-donnees",
      "metadata": {
        "id": "exploration-donnees"
      },
      "source": [
        "# 🔍 Exploration et Visualisation des Données\n",
        "\n",
        "Dans cette section, nous allons :\n",
        "\n",
        "- 🗂️ Afficher les premières lignes du dataset.\n",
        "- 📊 Obtenir des statistiques descriptives.\n",
        "- 📈 Visualiser la distribution des variables.\n",
        "- 🌐 Créer un nuage de points (scatter plot).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affichage-donnees",
      "metadata": {
        "id": "affichage-donnees"
      },
      "outputs": [],
      "source": [
        "# Affichage des premières lignes\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statistiques-descriptives",
      "metadata": {
        "id": "statistiques-descriptives"
      },
      "outputs": [],
      "source": [
        "# Statistiques descriptives\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interpretation-statistiques",
      "metadata": {
        "id": "interpretation-statistiques"
      },
      "source": [
        "**Interprétation** : Les statistiques descriptives nous donnent des informations sur la moyenne, l'écart-type, les valeurs minimales et maximales, et les quartiles des variables 'Fertilizer' et 'Yield'. Cela nous aide à comprendre la distribution et la dispersion des données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distribution-variables",
      "metadata": {
        "id": "distribution-variables"
      },
      "outputs": [],
      "source": [
        "# Visualisation de la distribution des variables\n",
        "\n",
        "# Histogramme de Fertilizer\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(data['Fertilizer'], kde=True, color='green')\n",
        "plt.title('Distribution de la Quantité de Fertilisant')\n",
        "\n",
        "# Histogramme de Yield\n",
        "plt.subplot(1,2,2)\n",
        "sns.histplot(data['Yield'], kde=True, color='orange')\n",
        "plt.title('Distribution du Rendement en Céréales')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nuage-points",
      "metadata": {
        "id": "nuage-points"
      },
      "outputs": [],
      "source": [
        "# Création d'un nuage de points\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='Fertilizer', y='Yield', data=data)\n",
        "plt.title('Relation entre le Fertilisant et le Rendement')\n",
        "plt.xlabel('Quantité de Fertilisant (kg/ha)')\n",
        "plt.ylabel('Rendement (tonnes/ha)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pretraitement-donnees",
      "metadata": {
        "id": "pretraitement-donnees"
      },
      "source": [
        "# 🧹 Prétraitement des Données\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- 🔍 Vérifier les valeurs manquantes.\n",
        "- ⚠️ Détecter et traiter les valeurs aberrantes.\n",
        "- 🧪 Séparer les données en ensembles d'entraînement et de test.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valeurs-manquantes",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "valeurs-manquantes",
        "outputId": "2725fd9e-93f7-4ae1-f919-c0f3f0f914b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fertilizer    0\n",
              "Yield         0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fertilizer</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Yield</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Vérification des valeurs manquantes\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "traitement-valeurs-aberrantes",
      "metadata": {
        "id": "traitement-valeurs-aberrantes"
      },
      "source": [
        "## 🚨 Détection et Traitement des Valeurs Aberrantes\n",
        "\n",
        "Nous utilisons des **boîtes à moustaches** pour détecter les outliers.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boxplot-outliers",
      "metadata": {
        "id": "boxplot-outliers"
      },
      "outputs": [],
      "source": [
        "# Boîte à moustaches pour détecter les outliers\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(y='Fertilizer', data=data, color='green')\n",
        "plt.title('Boîte à moustaches de Fertilizer')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(y='Yield', data=data, color='orange')\n",
        "plt.title('Boîte à moustaches de Yield')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "separation-ensembles",
      "metadata": {
        "id": "separation-ensembles"
      },
      "source": [
        "## 🧪 Séparation des Données en Ensembles d'Entraînement et de Test\n",
        "\n",
        "Nous séparons les données pour évaluer le modèle sur des données non vues.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-test-split",
      "metadata": {
        "id": "train-test-split"
      },
      "outputs": [],
      "source": [
        "# Séparation des variables indépendantes et dépendantes\n",
        "X = data[['Fertilizer']]\n",
        "y = data['Yield']\n",
        "\n",
        "# Division en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "implementation-modele",
      "metadata": {
        "id": "implementation-modele"
      },
      "source": [
        "# 📐 Implémentation de la Régression Linéaire Simple\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- ✏️ Calculer manuellement les coefficients.\n",
        "- ⚙️ Utiliser la classe `LinearRegression` de scikit-learn.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "calcul-manuel-coefficients",
      "metadata": {
        "id": "calcul-manuel-coefficients"
      },
      "source": [
        "## ✏️ Calcul Manuel des Coefficients\n",
        "\n",
        "Nous utilisons la formule des **moindres carrés ordinaires (OLS)** pour calculer les coefficients :\n",
        "\n",
        "$$\n",
        "\\beta = (X^T X)^{-1} X^T y\n",
        "$$\n",
        "\n",
        "### Explication de la formule\n",
        "\n",
        "- **\\( \\beta \\)** : Ce sont les coefficients de la régression linéaire que nous voulons déterminer. Ils définissent la relation entre les variables indépendantes (X) et la variable dépendante (y).\n",
        "- **\\( X^T \\)** : Il s'agit de la transposée de la matrice \\( X \\), qui contient les valeurs de la variable indépendante.\n",
        "- **\\( X^T X \\)** : En multipliant \\( X^T \\) par \\( X \\), nous obtenons une matrice carrée. Cette multiplication est une étape clé pour comprendre comment la variable indépendante influence la variable dépendante.\n",
        "- **\\( (X^T X)^{-1} \\)** : On calcule ensuite l'inverse de cette matrice. Cela permet de \"défaire\" l'influence de \\( X \\) pour isoler le terme \\( \\beta \\).\n",
        "- **\\( X^T y \\)** : Enfin, on multiplie la transposée de \\( X \\) par \\( y \\), ce qui intègre l'influence de la variable dépendante.\n",
        "\n",
        "En combinant ces étapes, la formule nous donne les valeurs des coefficients \\( \\beta \\) qui minimisent la somme des carrés des écarts entre les valeurs prédites et les valeurs réelles, nous offrant ainsi la meilleure droite de régression.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "calcul-coefficients",
      "metadata": {
        "id": "calcul-coefficients"
      },
      "outputs": [],
      "source": [
        "# Ajout d'une colonne de biais (interception)\n",
        "X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
        "\n",
        "# Calcul des coefficients\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
        "\n",
        "print(f\"Ordonnée à l'origine (interception): {theta_best[0]:.2f}\")\n",
        "print(f\"Pente: {theta_best[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "utilisation-scikit-learn",
      "metadata": {
        "id": "utilisation-scikit-learn"
      },
      "source": [
        "## ⚙️ Utilisation de la Classe `LinearRegression`\n",
        "\n",
        "Nous utilisons **scikit-learn** pour entraîner le modèle de régression linéaire de manière simple et efficace.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entrainement-modele",
      "metadata": {
        "id": "entrainement-modele"
      },
      "outputs": [],
      "source": [
        "# Création du modèle\n",
        "model = LinearRegression()\n",
        "\n",
        "# Entraînement du modèle\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Coefficients du modèle\n",
        "print(f\"Ordonnée à l'origine (interception): {model.intercept_:.2f}\")\n",
        "print(f\"Pente: {model.coef_[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "evaluation-modele",
      "metadata": {
        "id": "evaluation-modele"
      },
      "source": [
        "# 📊 Évaluation du Modèle\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- 📏 Calculer les métriques de performance.\n",
        "- 🔍 Interpréter les résultats.\n",
        "\n",
        "## Détails des Étapes\n",
        "\n",
        "### Calcul des Métriques de Performance\n",
        "\n",
        "Pour évaluer la précision du modèle, nous calculons plusieurs métriques de performance :\n",
        "\n",
        "1. **Mean Squared Error (MSE)** :\n",
        "   - **Formule** : \\( \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{test} - y_{pred})^2 \\)\n",
        "   - **Explication** : Le MSE mesure la moyenne des carrés des erreurs (différences entre les valeurs réelles \\( y_{test} \\) et les valeurs prédites \\( y_{pred} \\)). Un MSE plus faible signifie que les prédictions sont globalement proches des valeurs observées.\n",
        "\n",
        "2. **Root Mean Squared Error (RMSE)** :\n",
        "   - **Formule** : \\( \\text{RMSE} = \\sqrt{\\text{MSE}} \\)\n",
        "   - **Explication** : Le RMSE est la racine carrée de la MSE, exprimée dans la même unité que la variable cible. Cela permet d'interpréter l'erreur moyenne de manière intuitive.\n",
        "\n",
        "3. **Mean Absolute Error (MAE)** :\n",
        "   - **Formule** : \\( \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{test} - y_{pred}| \\)\n",
        "   - **Explication** : Le MAE mesure l'erreur moyenne absolue, sans considérer la direction de l'erreur (positif ou négatif). Cela donne une estimation directe de l'écart moyen entre les prédictions et les valeurs réelles.\n",
        "\n",
        "4. **Coefficient de Détermination (R²)** :\n",
        "   - **Formule** : \\( R^2 = 1 - \\frac{\\sum (y_{test} - y_{pred})^2}{\\sum (y_{test} - \\bar{y}_{test})^2} \\)\n",
        "   - **Explication** : Le coefficient \\( R^2 \\) mesure la proportion de variance de la variable cible expliquée par le modèle. Un \\( R^2 \\) proche de 1 indique que le modèle est performant, tandis qu'un \\( R^2 \\) proche de 0 signale un modèle peu explicatif.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "calcul-metrics",
      "metadata": {
        "id": "calcul-metrics"
      },
      "outputs": [],
      "source": [
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcul des métriques\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Coefficient de Détermination (R²): {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interpretation-resultats",
      "metadata": {
        "id": "interpretation-resultats"
      },
      "source": [
        "## 🔍 Interprétation des Résultats\n",
        "\n",
        "- **MSE** : Plus la valeur est faible, meilleure est la précision moyenne des prédictions.\n",
        "- **RMSE** : Indique l'erreur moyenne en unités de la variable cible pour une interprétation directe.\n",
        "- **MAE** : Mesure l'écart moyen absolu entre les prédictions et les valeurs réelles.\n",
        "- **R²** : Proche de 1, il indique que le modèle explique bien la variance des données.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "visualisation-resultats",
      "metadata": {
        "id": "visualisation-resultats"
      },
      "source": [
        "# 📉 Visualisation des Résultats\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- 📏 **Tracer la droite de régression** : Cela consiste à représenter graphiquement la droite de régression calculée par le modèle. En superposant cette droite aux données observées, nous pouvons visualiser comment le modèle ajuste les prédictions par rapport aux valeurs réelles. Plus la droite suit bien la tendance des points de données, meilleur est l’ajustement du modèle.\n",
        "  \n",
        "- 🔍 **Visualiser les résidus** : Les résidus sont les différences entre les valeurs observées et les valeurs prédites par le modèle. En traçant un graphique des résidus, nous pouvons analyser la qualité de l’ajustement du modèle. Idéalement, les résidus devraient être distribués aléatoirement autour de zéro, ce qui indiquerait que le modèle est bien ajusté. Si les résidus montrent un motif ou une tendance, cela peut révéler des biais dans le modèle ou des relations non linéaires dans les données.\n",
        "\n",
        "Ces visualisations permettent de mieux comprendre comment le modèle se comporte et d’identifier les zones d’amélioration potentielles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trace-droite-regression",
      "metadata": {
        "id": "trace-droite-regression"
      },
      "outputs": [],
      "source": [
        "# Tracé de la droite de régression sur le nuage de points\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Données d\\'entraînement')\n",
        "plt.plot(X_train, model.predict(X_train), color='red', label='Modèle entraîné')\n",
        "plt.title('Régression Linéaire - Ensemble d\\'entraînement')\n",
        "plt.xlabel('Quantité de Fertilisant (kg/ha)')\n",
        "plt.ylabel('Rendement (tonnes/ha)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "visualisation-residus",
      "metadata": {
        "id": "visualisation-residus"
      },
      "outputs": [],
      "source": [
        "# Visualisation des résidus\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=y_pred, y=residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Graphique des résidus')\n",
        "plt.xlabel('Valeurs prédites')\n",
        "plt.ylabel('Résidus')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interpretation-residus",
      "metadata": {
        "id": "interpretation-residus"
      },
      "source": [
        "**Interprétation** : Le graphique des résidus montre la différence entre les valeurs réelles et les valeurs prédites par le modèle (les résidus).\n",
        "\n",
        "- **Homoscedasticité** : Idéalement, les résidus doivent être dispersés de manière uniforme autour de la ligne zéro, sans former de motifs particuliers. Cette distribution constante des résidus confirme l’hypothèse d’homoscedasticité, indiquant que le modèle maintient une erreur constante quelle que soit la valeur prédite.\n",
        "\n",
        "- **Détection des motifs** : Si le graphique des résidus révèle une tendance (par exemple, une forme courbe ou des groupes), cela pourrait indiquer un problème d'adéquation du modèle. Une telle structure peut suggérer que la relation entre les variables n’est pas strictement linéaire ou qu’une variable explicative manque dans le modèle.\n",
        "\n",
        "En somme, ce graphique est essentiel pour évaluer l'ajustement du modèle et identifier des biais ou des erreurs d'ajustement potentiels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "predictions-modele",
      "metadata": {
        "id": "predictions-modele"
      },
      "source": [
        "# 🔮 Prédictions avec le Modèle\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- 🧩 **Utiliser le modèle pour faire des prédictions** sur de nouvelles données : Une fois le modèle entraîné, nous pouvons l'appliquer pour prédire les valeurs de la variable dépendante à partir de nouvelles valeurs de la variable indépendante.\n",
        "  \n",
        "- 📊 **Interpréter les prédictions** : En analysant les résultats obtenus, nous pouvons évaluer si les prédictions sont cohérentes et dans quelle mesure elles répondent aux attentes. Cette étape permet de valider l’utilité du modèle dans des scénarios réels et d’identifier d’éventuelles limites ou ajustements nécessaires.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nouvelles-predictions",
      "metadata": {
        "id": "nouvelles-predictions"
      },
      "outputs": [],
      "source": [
        "# Nouvelles données (quantités de fertilisant) sous forme de DataFrame pandas\n",
        "X_new = pd.DataFrame({'Fertilizer': [10, 50, 90]})\n",
        "\n",
        "# Prédictions\n",
        "y_new = model.predict(X_new)\n",
        "\n",
        "# Affichage des prédictions\n",
        "for i, x in enumerate(X_new['Fertilizer']):\n",
        "    print(f\"Pour une quantité de fertilisant de {x} kg/ha, le rendement prédit est de {y_new[i]:.2f} tonnes/ha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interpretation-predictions",
      "metadata": {
        "id": "interpretation-predictions"
      },
      "source": [
        "## 📈 Interprétation des Prédictions\n",
        "\n",
        "Le modèle nous permet d'estimer le rendement en fonction de la quantité de fertilisant appliquée. Ces prédictions peuvent être précieuses pour les agriculteurs, car elles les aident à :\n",
        "\n",
        "- **Optimiser l’utilisation des ressources** : En connaissant le rendement prédit pour différentes quantités de fertilisant, les agriculteurs peuvent ajuster les doses appliquées pour maximiser le rendement tout en minimisant les coûts.\n",
        "  \n",
        "- **Planifier les récoltes** : Avec des prédictions fiables, il devient plus facile de prévoir le rendement total attendu, ce qui aide à mieux organiser la logistique, le stockage, et la distribution.\n",
        "\n",
        "En somme, ces prédictions fournissent un outil de prise de décision pour une gestion agricole plus efficace et durable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostic-modele",
      "metadata": {
        "id": "diagnostic-modele"
      },
      "source": [
        "# 🩺 Diagnostic du Modèle\n",
        "\n",
        "Nous allons :\n",
        "\n",
        "- **Vérifier les hypothèses de la régression linéaire** : Ces hypothèses sont essentielles pour s'assurer que le modèle est approprié pour les données et que les résultats sont fiables. Nous allons examiner des éléments tels que la linéarité, l'indépendance des erreurs, l'homoscedasticité (variance constante des erreurs), et la normalité des erreurs. Si ces hypothèses sont vérifiées, cela indique que notre modèle est bien ajusté aux données. En revanche, des violations de ces hypothèses peuvent signaler un besoin de réviser le modèle ou d'envisager des alternatives.\n",
        "\n",
        "- **Analyser les résidus** : Les résidus, qui représentent les différences entre les valeurs observées et prédites, fournissent des informations clés sur la qualité de l'ajustement du modèle. En analysant leur distribution, nous pouvons vérifier si les erreurs sont réparties de manière aléatoire (un bon signe) ou s’il existe des motifs (indiquant des biais ou des ajustements nécessaires). Un graphique des résidus peut par exemple révéler des erreurs systématiques ou des relations non linéaires non capturées par le modèle.\n",
        "\n",
        "Ces étapes de diagnostic sont cruciales pour évaluer la robustesse et la fiabilité du modèle de régression linéaire, en identifiant les limites potentielles et en garantissant des prédictions de qualité.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verification-hypotheses",
      "metadata": {
        "id": "verification-hypotheses"
      },
      "outputs": [],
      "source": [
        "# Vérification de la normalité des résidus\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(residuals, kde=True, color='purple')\n",
        "plt.title('Distribution des résidus')\n",
        "plt.xlabel('Résidus')\n",
        "plt.ylabel('Fréquence')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analyse-residus",
      "metadata": {
        "id": "analyse-residus"
      },
      "source": [
        "## 🔍 Analyse des Résidus\n",
        "\n",
        "Si les résidus suivent une **distribution normale** centrée autour de zéro, cela indique que les hypothèses du modèle de régression linéaire sont globalement satisfaites. Plus précisément :\n",
        "\n",
        "- **Centrée autour de zéro** : Les résidus devraient se répartir de manière équilibrée autour de zéro. Cela signifie que le modèle n’a pas de biais systématique, et que les prédictions ne sont pas constamment sous- ou sur-estimées.\n",
        "\n",
        "- **Distribution normale** : Une distribution normale des résidus implique que les erreurs sont aléatoires et bien réparties, sans tendance spécifique. Cela est essentiel pour que le modèle soit considéré comme bien ajusté aux données, car cela respecte l'hypothèse de normalité des erreurs.\n",
        "\n",
        "En résumé, une distribution normale des résidus centrée autour de zéro est un signe positif, indiquant que le modèle est fiable et que les prédictions sont conformes aux attentes basées sur les hypothèses de la régression linéaire.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "amelioration-modele",
      "metadata": {
        "id": "amelioration-modele"
      },
      "source": [
        "# 🚀 Amélioration du Modèle\n",
        "\n",
        "## 🔧 Techniques pour Améliorer les Performances\n",
        "\n",
        "- **Transformation des variables** : Appliquer des transformations (comme le logarithme ou la racine carrée) pour linéariser les relations non linéaires entre les variables. Cela permet au modèle de capturer des variations qui seraient autrement ignorées.\n",
        "- **Ajout de variables explicatives** : Inclure d'autres facteurs pertinents qui influencent le rendement (par exemple, type de sol, précipitations, température). Cela enrichit le modèle et augmente sa capacité à expliquer la variabilité de la variable cible.\n",
        "- **Détection des outliers** : Identifier et traiter les valeurs aberrantes, car celles-ci peuvent fausser l'ajustement du modèle et influencer la précision des prédictions.\n",
        "\n",
        "## ⚠️ Limites de la Régression Linéaire Simple\n",
        "\n",
        "- **Simplicité du modèle** : La régression linéaire simple est limitée dans sa capacité à capturer des relations complexes. Elle ne modélise que les relations linéaires entre deux variables et n'explique pas les interactions plus subtiles.\n",
        "- **Sensibilité aux outliers** : Les valeurs aberrantes ont un impact important sur la régression linéaire, pouvant fausser les résultats de manière significative.\n",
        "- **Suppositions strictes** : Le modèle repose sur des hypothèses strictes (linéarité, indépendance, homoscedasticité, normalité des erreurs). Dans la réalité, il peut être difficile de satisfaire ces conditions, ce qui limite l'applicabilité du modèle.\n",
        "\n",
        "---\n",
        "\n",
        "Ces techniques d'amélioration permettent de renforcer le modèle en le rendant plus flexible et en tenant compte de facteurs supplémentaires. Cependant, les limites soulignent la nécessité d'une attention particulière aux hypothèses et à la robustesse du modèle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion-recapitulatif",
      "metadata": {
        "id": "conclusion-recapitulatif"
      },
      "source": [
        "# 📌 Conclusion et Récapitulatif\n",
        "\n",
        "Nous avons :\n",
        "\n",
        "- **Exploré** le concept de régression linéaire simple et ses applications dans le contexte agricole.\n",
        "- **Créé** un dataset synthétique pour simuler la relation entre le fertilisant et le rendement.\n",
        "- **Implémenté** le modèle de régression linéaire simple manuellement et avec scikit-learn.\n",
        "- **Évalué** le modèle en utilisant diverses métriques et en analysant les résidus.\n",
        "- **Discuté** des moyens d'améliorer le modèle et des limites de la régression linéaire simple.\n",
        "\n",
        "---\n",
        "\n",
        "**Auteur :** Omar Kennouche, fondateur de **AI Nexus One**  \n",
        "**Contact** : [contact@topdeveloppement.tech](mailto:contact@topdeveloppement.tech)\n",
        "\n",
        "*Merci d'avoir suivi ce notebook ! N'hésitez pas à explorer davantage et à appliquer ces techniques à vos propres données.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercices-pratiques",
      "metadata": {
        "id": "exercices-pratiques"
      },
      "source": [
        "# 📝 Exercices Pratiques\n",
        "\n",
        "1. **Modifier le Dataset** : Changez les paramètres de la génération des données (par exemple, la relation entre le fertilisant et le rendement) et observez l'impact sur le modèle. Essayez de comprendre comment les modifications influencent les coefficients et la qualité de la prédiction.\n",
        "\n",
        "2. **Ajouter une Variable** : Incluez une nouvelle variable explicative (par exemple, le type de sol) et passez à une **régression linéaire multiple**. Cette extension du modèle vous permettra de voir comment plusieurs facteurs influencent simultanément le rendement.\n",
        "\n",
        "3. **Tester un Dataset Réel** : Utilisez un jeu de données réel lié à l'agriculture (par exemple, des données météorologiques ou de rendement agricole) et appliquez les mêmes étapes d’analyse et de modélisation. Comparez les résultats avec les données synthétiques et identifiez les différences.\n",
        "\n",
        "---\n",
        "\n",
        "Ces exercices vous permettront d'approfondir votre compréhension de la régression linéaire et d’explorer son application dans des scénarios plus complexes et réalistes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lexique-termes",
      "metadata": {
        "id": "lexique-termes"
      },
      "source": [
        "# 📖 Lexique des Termes Techniques\n",
        "\n",
        "- **Régression linéaire** : Méthode statistique pour modéliser la relation entre une variable dépendante et une ou plusieurs variables indépendantes.\n",
        "- **Variable indépendante** : Variable utilisée pour prédire la variable dépendante (ex : quantité de fertilisant).\n",
        "- **Variable dépendante** : Variable cible que l'on cherche à prédire (ex : rendement en céréales).\n",
        "- **Pente (Coefficient)** : Indique l'effet moyen d'une unité de changement de la variable indépendante sur la variable dépendante.\n",
        "- **Ordonnée à l'origine (Intercept)** : Valeur de la variable dépendante lorsque la variable indépendante est nulle.\n",
        "- **Résidu** : Différence entre la valeur observée et la valeur prédite par le modèle.\n",
        "- **MSE** : Mean Squared Error, moyenne des erreurs quadratiques. Mesure de la précision en prenant en compte les erreurs au carré.\n",
        "- **RMSE** : Root Mean Squared Error, racine carrée du MSE, exprimée dans les mêmes unités que la variable cible.\n",
        "- **MAE** : Mean Absolute Error, moyenne des erreurs absolues entre les valeurs prédites et observées.\n",
        "- **R²** : Coefficient de détermination, mesure la proportion de la variance de la variable cible expliquée par le modèle, indiquant sa qualité d'ajustement.\n",
        "\n",
        "---\n",
        "\n",
        "Ce lexique fournit une définition claire et concise des principaux termes techniques utilisés dans l'analyse de la régression linéaire.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ressources-supplementaires",
      "metadata": {
        "id": "ressources-supplementaires"
      },
      "source": [
        "# 📚 Ressources Supplémentaires\n",
        "\n",
        "- 📘 [Documentation Scikit-Learn - Régression Linéaire](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)\n",
        "- 🎓 [Cours sur la Régression Linéaire - OpenClassrooms](https://openclassrooms.com/fr/courses/4525286-realisez-des-analyses-statistiques-avec-python)\n",
        "- 🎥 [Introduction à la Régression Linéaire - StatQuest (Vidéo)](https://www.youtube.com/watch?v=nk2CQITm_eo)\n",
        "- 📖 [Livre : \"An Introduction to Statistical Learning\" - Chapitre sur la Régression Linéaire](https://www.statlearning.com/)\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}